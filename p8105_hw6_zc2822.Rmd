---
title: "p8105_hw6"
author: "Zhengyong Chen"
output: github_document
---

```{r setup, include=FALSE, message=FALSE}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(knitr)
library(modelr)
library(purrr)
library(forcats)
library(broom)
```

```{r}
set.seed(123)
```


## Problem 1

```{r message=FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


```{r}
bootstrap = function(data, n_bootstrap = 5000) {
  data |>
    modelr::bootstrap(n = n_bootstrap) |>
    mutate(
      models = map(strap, \(df) lm(tmax ~ tmin, data = as_tibble(df))),
      r_squared = map_dbl(models, \(mod) glance(mod)$r.squared),
      log_beta0_beta1 = map_dbl(models, \(mod) {
        coef_mod = tidy(mod)
        beta0 = coef_mod$estimate[coef_mod$term == "(Intercept)"]
        beta1 = coef_mod$estimate[coef_mod$term == "tmin"]
        log(beta0 * beta1)
      })
    ) |>
    select(r_squared, log_beta0_beta1)
}


bootstrap_results = bootstrap(weather_df, n_bootstrap = 5000)

conf_intervals =
  bootstrap_results |>
  summarise(
    r_squared_low = quantile(r_squared, 0.025),
    r_squared_high = quantile(r_squared, 0.975),
    log_beta0_beta1_low = quantile(log_beta0_beta1, 0.025),
    log_beta0_beta1_high = quantile(log_beta0_beta1, 0.975)
  )

conf_intervals |> 
  kable(caption = "95% confidence interval for R^2 and log(β0 * β1)",
        digits = 3)

bootstrap_results |>
  pivot_longer(cols = everything(), names_to = "metric", values_to = "value") |>
  ggplot(aes(x = value, fill = metric)) +
  geom_histogram(alpha = 0.6) +
  facet_wrap(~ metric, scales = "free") +
  labs(
    title = "Bootstrap Distributions of R^2 and log(β0 * β1)",
    x = "Value",
    y = "Density",
    fill = "Metric"
  ) +
  theme_minimal()
```

Both metrics show narrow, symmetric distributions, indicating consistent estimates from the bootstrap process. The distribution of $\log(\beta_0 \cdot \beta_1)$ is approximately normal, centered around 2. The distribution of $R^2$ is also approximately normal, centered around 0.91.

## Problem 2

```{r load data, message=FALSE}
homicide = read_csv("data/homicide-data.csv")
```

**Create a city_state variable, and a binary variable indicating whether the homicide is solved.**

```{r}
homicide = homicide |>
  mutate(city_state = paste(city, state, sep = ", ")) |>
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")),
    victim_race %in% c("White", "Black"),
    victim_age != "Unknown"
  ) |>
  mutate(solved = ifelse(grepl("Closed", disposition, ignore.case = TRUE), 1, 0),
         victim_age = as.numeric(victim_age))
```


**Logistic regression for Baltimore**

```{r}
baltimore_data = homicide |>
  filter(city_state == "Baltimore, MD") |> 
  mutate(victim_sex = factor(victim_sex, levels = c("Female", "Male")))

glm_fit = glm(
  solved ~ victim_age + victim_sex + victim_race,
  data = baltimore_data,
  family = binomial
)

glm_results = broom::tidy(glm_fit, conf.int = TRUE, exponentiate = TRUE)

glm_results |>
  filter(term == "victim_sexMale") |>
  select(estimate, conf.low, conf.high) |> 
  kable(
    col.names = c("Adjusted OR", "Lower CI", "Upper CI"),
    caption = "Adjusted Odds Ratio for Solving Homicides (Male vs Female)",
    digits = 3
  )
```

**glm for each of the cities**

```{r warning=FALSE}
city_results = homicide |>
  group_by(city_state) |>
  nest() |>
  mutate(
    glm_fit = map(data, ~ glm(
      solved ~ victim_age + victim_sex + victim_race,
      data = .x,
      family = binomial
    )),
    glm_tidy = map(glm_fit, ~ broom::tidy(.x, conf.int = TRUE, exponentiate = TRUE))
  ) |>
  unnest(glm_tidy) |>
  filter(term == "victim_sexMale") |>
  select(city_state, estimate, conf.low, conf.high)

city_results |>
  kable(
    col.names = c("City, State", "Adjusted Odds Ratio", "Lower CI", "Upper CI"),
    caption = "Adjusted Odds Ratios for Solving Homicides (Male vs Female) by City", 
    digits = 3,
    options = list(pageLength = 10)
  ) 
```

**plot**

```{r}
city_results |>
  arrange(estimate) |>
  ggplot(aes(x = estimate, y = reorder(city_state, estimate))) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2) +
  labs(
    x = "Adjusted Odds Ratio (Male vs Female)",
    y = "City, State",
    title = "Adjusted Odds Ratios for Solving Homicides by City",
  ) +
  theme_minimal()
```

Comment:\
Several cities (Fresno, Minneapolis, and Stockton) show ORs above 1, suggesting male victims are more likely to have their cases solved, while others are below 1, indicating in most cities, female victims are more likely to have their cases solved. New York has the smallest adjusted odds ratio. Some cities like Fresno and Stockton has wider confidence intervals, indicating less precise estimates.


## Problem 3

**Load and clean the data.**

```{r}

birthweight = read.csv("data/birthweight.csv") 

birthweight = birthweight |>
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("Male", "Female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1), labels = c("Absent", "Present")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other"))
  ) 

birthweight |>
  summarise_all(~ sum(is.na(.)))
```

I will use a hypothesized structure for the factors that underly birthweight. I think it would be reasonable to include gaweeks, momage, mheight, wtgain, and babysex.

```{r}
model_hypothesis = lm(
  bwt ~ gaweeks + momage + mheight + wtgain + babysex,
  data = birthweight
)

birthweight = birthweight |>
  add_predictions(model_hypothesis, var = "fitted") |>
  add_residuals(model_hypothesis, var = "residual")

ggplot(birthweight, aes(x = fitted, y = residual)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    x = "Fitted Values",
    y = "Residuals",
    title = "Residuals vs Fitted Values"
  ) +
  theme_minimal()
```

**Comparison**

```{r}
cv_df = crossv_mc(birthweight, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_df = cv_df |> 
  mutate(
    hypothesis_mod = map(train, \(df) lm(bwt ~ gaweeks + momage + mheight + wtgain + babysex, data = df)),
    length_gest_mod = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    full_interaction_mod = map(train, \(df) lm(bwt ~ bhead * blength * babysex, data = df))
  ) |> 
  mutate(
    rmse_hypothesis = map2_dbl(hypothesis_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_length_gest = map2_dbl(length_gest_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_full_interaction = map2_dbl(full_interaction_mod, test, \(mod, df) rmse(model = mod, data = df))
  )

cv_summary = cv_df|>
  summarise(
    hypothesis_mean_error = mean(rmse_hypothesis),
    length_gest_mean_error = mean(rmse_length_gest),
    full_interaction_mean_error = mean(rmse_full_interaction)
  )

cv_summary |> 
  kable()
```

``` {r}
rmse_results = cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) |> 
  mutate(model = fct_inorder(model))

ggplot(rmse_results, aes(x = model, y = rmse)) +
  geom_violin() +
  labs(
    x = "Model",
    y = "RMSE",
    title = "Comparison of RMSE Distributions Across Models"
  ) +
  theme_minimal()
```


